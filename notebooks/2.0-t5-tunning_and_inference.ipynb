{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:11:35.645147800Z",
     "start_time": "2023-10-22T09:11:35.433678600Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:11:35.660955800Z",
     "start_time": "2023-10-22T09:11:35.647148100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = \"../data/raw/filtered.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:11:36.759701600Z",
     "start_time": "2023-10-22T09:11:35.662956500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm not gonna have a child... ...with the same...</td>\n",
       "      <td>I'm not going to breed kids with a genetic dis...</td>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.950956</td>\n",
       "      <td>0.035846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>They're all laughing at us, so we'll kick your...</td>\n",
       "      <td>they're laughing at us. We'll show you.</td>\n",
       "      <td>0.618866</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Maine was very short on black people back then.</td>\n",
       "      <td>there wasn't much black in Maine then.</td>\n",
       "      <td>0.720482</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.963680</td>\n",
       "      <td>0.148710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Briggs, what the hell's happening?</td>\n",
       "      <td>Briggs, what the hell is going on?</td>\n",
       "      <td>0.920373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159096</td>\n",
       "      <td>0.841071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Another one simply had no clue what to do, so ...</td>\n",
       "      <td>another simply didn't know what to do, so when...</td>\n",
       "      <td>0.877540</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.055371</td>\n",
       "      <td>0.930472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          reference  \\\n",
       "0           0  If Alkar is flooding her with psychic waste, t...   \n",
       "1           1                          Now you're getting nasty.   \n",
       "2           2           Well, we could spare your life, for one.   \n",
       "3           3          Ah! Monkey, you've got to snap out of it.   \n",
       "4           4                   I've got orders to put her down.   \n",
       "5           5  I'm not gonna have a child... ...with the same...   \n",
       "6           6  They're all laughing at us, so we'll kick your...   \n",
       "7           7    Maine was very short on black people back then.   \n",
       "8           8                 Briggs, what the hell's happening?   \n",
       "9           9  Another one simply had no clue what to do, so ...   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309   \n",
       "1                        you're becoming disgusting.    0.749687     0.071429   \n",
       "2                      well, we can spare your life.    0.919051     0.268293   \n",
       "3                       monkey, you have to wake up.    0.664333     0.309524   \n",
       "4                         I have orders to kill her.    0.726639     0.181818   \n",
       "5  I'm not going to breed kids with a genetic dis...    0.703185     0.206522   \n",
       "6            they're laughing at us. We'll show you.    0.618866     0.230769   \n",
       "7             there wasn't much black in Maine then.    0.720482     0.187500   \n",
       "8                 Briggs, what the hell is going on?    0.920373     0.000000   \n",
       "9  another simply didn't know what to do, so when...    0.877540     0.101695   \n",
       "\n",
       "    ref_tox   trn_tox  \n",
       "0  0.014195  0.981983  \n",
       "1  0.065473  0.999039  \n",
       "2  0.213313  0.985068  \n",
       "3  0.053362  0.994215  \n",
       "4  0.009402  0.999348  \n",
       "5  0.950956  0.035846  \n",
       "6  0.999492  0.000131  \n",
       "7  0.963680  0.148710  \n",
       "8  0.159096  0.841071  \n",
       "9  0.055371  0.930472  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset, sep=\"\\t\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:02.841828600Z",
     "start_time": "2023-10-22T09:11:36.767701600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "references = [row.reference if row.ref_tox > row.trn_tox else row.translation for i, row in df.iterrows()]\n",
    "translations = [row.translation if row.ref_tox > row.trn_tox else row.reference for i, row in df.iterrows()]\n",
    "inference_df = pd.DataFrame({'references': references, 'translations': translations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:02.856524700Z",
     "start_time": "2023-10-22T09:12:02.842828800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer_name = \"ceshine/t5-paraphrase-paws-msrp-opinosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:03.747542700Z",
     "start_time": "2023-10-22T09:12:02.857526200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5TokenizerFast\n",
    "\n",
    "tokenizer = T5TokenizerFast.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:04.063270300Z",
     "start_time": "2023-10-22T09:12:03.748542300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(inference_df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:15.614780300Z",
     "start_time": "2023-10-22T09:12:04.065270800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_references = tokenizer(df_train.references.tolist(), truncation=True)\n",
    "train_translations = tokenizer(df_train.translations.tolist(), truncation=True)\n",
    "test_references = tokenizer(df_test.references.tolist(), truncation=True)\n",
    "test_translations = tokenizer(df_test.translations.tolist(), truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:16.336215100Z",
     "start_time": "2023-10-22T09:12:15.615779900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(519999, 57778)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class DetoxDataset(Dataset):\n",
    "    def __init__(self, references, translations):\n",
    "        self.references = references\n",
    "        self.translations = translations\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert idx < len(self.references['input_ids'])\n",
    "        item = {key: val[idx] for key, val in self.references.items()}\n",
    "        item['decoder_attention_mask'] = self.translations['attention_mask'][idx]\n",
    "        item['labels'] = self.translations['input_ids'][idx]\n",
    "        return item\n",
    "\n",
    "    @property\n",
    "    def n(self):\n",
    "        return len(self.references['input_ids'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "train_dataset = DetoxDataset(train_references, train_translations)\n",
    "test_dataset = DetoxDataset(test_references, test_translations)\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:16.382595900Z",
     "start_time": "2023-10-22T09:12:16.337216100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, drop_last=True, shuffle=True, num_workers=1)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, drop_last=True, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:16.386600600Z",
     "start_time": "2023-10-22T09:12:16.354839Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "language_model_name = 'SkolkovoInstitute/t5-paraphrase-paws-msrp-opinosis-paranmt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:18.520459200Z",
     "start_time": "2023-10-22T09:12:16.382595900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(language_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:18.803198300Z",
     "start_time": "2023-10-22T09:12:18.538305400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:18.818419300Z",
     "start_time": "2023-10-22T09:12:18.808199300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Union\n",
    "\n",
    "class DataCollatorWithPadding:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=True,\n",
    "        )\n",
    "        ybatch = self.tokenizer.pad(\n",
    "            {'input_ids': batch['labels'], 'attention_mask': batch['decoder_attention_mask']},\n",
    "            padding=True,\n",
    "        )\n",
    "        batch['labels'] = ybatch['input_ids']\n",
    "        batch['decoder_attention_mask'] = ybatch['attention_mask']\n",
    "\n",
    "        return {k: torch.tensor(v) for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:18.837419700Z",
     "start_time": "2023-10-22T09:12:18.819419700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_name = 'models/t5-detox'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:20.166549300Z",
     "start_time": "2023-10-22T09:12:18.835419600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=save_name,   # output directory\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,             # total # of training epochs\n",
    "    per_device_train_batch_size=4,  # batch size per device during training\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=8,    # batch size for evaluation\n",
    "    warmup_steps=300,               # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0,                  # strength of weight decay\n",
    "    learning_rate=3e-5,\n",
    "    logging_dir='./logs',           # directory for storing logs\n",
    "    logging_steps=100,\n",
    "    eval_steps=100,\n",
    "\n",
    "    evaluation_strategy='steps',\n",
    "    save_total_limit=1,\n",
    "    save_steps=5000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:20.181548Z",
     "start_time": "2023-10-22T09:12:20.167549800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:20.227064400Z",
     "start_time": "2023-10-22T09:12:20.183548200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,           # evaluation dataset\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T09:12:20.972560600Z",
     "start_time": "2023-10-22T09:12:20.229064800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:50:25.738449Z",
     "start_time": "2023-10-22T09:12:20.972560600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='97500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    2/97500 : < :, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_7864\\49973641.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1647\u001B[0m             \u001B[0mresume_from_checkpoint\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mresume_from_checkpoint\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1648\u001B[0m             \u001B[0mtrial\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1649\u001B[1;33m             \u001B[0mignore_keys_for_eval\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mignore_keys_for_eval\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1650\u001B[0m         )\n\u001B[0;32m   1651\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36m_inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2018\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontrol\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcallback_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_step_end\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontrol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2019\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2020\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_log_save_evaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtr_loss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrial\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mignore_keys_for_eval\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2021\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2022\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontrol\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcallback_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_substep_end\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontrol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36m_maybe_log_save_evaluate\u001B[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2319\u001B[0m                     \u001B[0mmetrics\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset_metrics\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2320\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2321\u001B[1;33m                 \u001B[0mmetrics\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mignore_keys\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mignore_keys_for_eval\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2322\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_report_to_hp_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrial\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mglobal_step\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2323\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36mevaluate\u001B[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   3058\u001B[0m             \u001B[0mprediction_loss_only\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompute_metrics\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3059\u001B[0m             \u001B[0mignore_keys\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mignore_keys\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3060\u001B[1;33m             \u001B[0mmetric_key_prefix\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmetric_key_prefix\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3061\u001B[0m         )\n\u001B[0;32m   3062\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36mevaluation_loop\u001B[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   3243\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3244\u001B[0m             \u001B[1;31m# Prediction step\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3245\u001B[1;33m             \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogits\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprediction_step\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprediction_loss_only\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mignore_keys\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mignore_keys\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3246\u001B[0m             \u001B[0minputs_decode\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_prepare_input\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"input_ids\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minclude_inputs_for_metrics\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3247\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36mprediction_step\u001B[1;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001B[0m\n\u001B[0;32m   3501\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mhas_labels\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mloss_without_labels\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3502\u001B[0m                     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompute_loss_context_manager\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3503\u001B[1;33m                         \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompute_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3504\u001B[0m                     \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3505\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36mcompute_loss\u001B[1;34m(self, model, inputs, return_outputs)\u001B[0m\n\u001B[0;32m   2782\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2783\u001B[0m             \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2784\u001B[1;33m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2785\u001B[0m         \u001B[1;31m# Save past state if it exists\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2786\u001B[0m         \u001B[1;31m# TODO: this needs to be fixed and made cleaner later.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1730\u001B[0m             \u001B[0moutput_attentions\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moutput_attentions\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1731\u001B[0m             \u001B[0moutput_hidden_states\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moutput_hidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1732\u001B[1;33m             \u001B[0mreturn_dict\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mreturn_dict\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1733\u001B[0m         )\n\u001B[0;32m   1734\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1099\u001B[0m                     \u001B[0mpast_key_value\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpast_key_value\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1100\u001B[0m                     \u001B[0muse_cache\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muse_cache\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1101\u001B[1;33m                     \u001B[0moutput_attentions\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moutput_attentions\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1102\u001B[0m                 )\n\u001B[0;32m   1103\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001B[0m\n\u001B[0;32m    730\u001B[0m                 \u001B[0mquery_length\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mquery_length\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    731\u001B[0m                 \u001B[0muse_cache\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muse_cache\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 732\u001B[1;33m                 \u001B[0moutput_attentions\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moutput_attentions\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    733\u001B[0m             )\n\u001B[0;32m    734\u001B[0m             \u001B[0mhidden_states\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcross_attention_outputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions)\u001B[0m\n\u001B[0;32m    641\u001B[0m             \u001B[0muse_cache\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muse_cache\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    642\u001B[0m             \u001B[0mquery_length\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mquery_length\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 643\u001B[1;33m             \u001B[0moutput_attentions\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moutput_attentions\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    644\u001B[0m         )\n\u001B[0;32m    645\u001B[0m         \u001B[0mlayer_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhidden_states\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mattention_output\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001B[0m\n\u001B[0;32m    558\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    559\u001B[0m         \u001B[0mscores\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mposition_bias_masked\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 560\u001B[1;33m         attn_weights = nn.functional.softmax(scores.float(), dim=-1).type_as(\n\u001B[0m\u001B[0;32m    561\u001B[0m             \u001B[0mscores\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    562\u001B[0m         )  # (batch_size, n_heads, seq_length, key_length)\n",
      "\u001B[1;32mc:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36msoftmax\u001B[1;34m(input, dim, _stacklevel, dtype)\u001B[0m\n\u001B[0;32m   1839\u001B[0m         \u001B[0mdim\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_get_softmax_dim\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"softmax\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdim\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_stacklevel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1840\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1841\u001B[1;33m         \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msoftmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1842\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1843\u001B[0m         \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msoftmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:54:13.755632500Z",
     "start_time": "2023-10-22T12:50:33.448454700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8115463852882385}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:56:38.477315300Z",
     "start_time": "2023-10-22T12:56:36.236079600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer.save_model(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:55:39.944147200Z",
     "start_time": "2023-10-22T12:55:39.926024600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T12:55:48.886460800Z",
     "start_time": "2023-10-22T12:55:48.368188800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\esire\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\generation\\utils.py:1357: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Trump administration's internal policy is stupid.\n",
      "the internal policy of Trump is stupid.\n",
      "the internal policy of Donald Trump is stupid.\n",
      "the internal policy of President Trump is stupid.\n",
      "the Trump administration's internal policy is nonsense.\n",
      "the internal policy of Donald Trump is nonsense.\n",
      "the Trump administration's internal policy is bad.\n",
      "the internal policy of Mr. Trump is stupid.\n",
      "the internal policy of Trump is nonsense.\n",
      "the Trump internal policy is stupid.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer('The internal policy of the fucking Trump is stupid.', return_tensors='pt')\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "for t in model.generate(**inputs, num_return_sequences=10, do_sample=False, num_beams=10):\n",
    "    print(tokenizer.decode(t, skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
